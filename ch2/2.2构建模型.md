<!--
By working with probabilities instead of raw counts, Bayesian inference is made much easier, but it looks much harder. So in this section, we follow up on the garden of forking data by presenting the conventional form of a Bayesian statistical model. The toy example we’ll use here has the anatomy of a typical statistical analysis, so it’s the style that you’ll grow accustomed to. But every piece of it can be mapped onto the garden of forking data. The logic is the same.
-->
&emsp;&emsp;通过把原始的数值转换为概率，贝叶斯推断变容易了，但是看上去更困难一些。所以本节沿用花园路径的模式来看一下贝叶斯统计模型。示例是一个典型的统计分析，所以需要慢慢熟悉起来。但是每一部分都能在花园路径的模式中找到映射。逻辑是一样的。

<!--
Suppose you have a globe representing our planet, the Earth. This version of the world is small enough to hold in your hands. You are curious how much of the surface is covered in water. You adopt the following strategy: You will toss the globe up in the air. When you catch it, you will record whether or not the surface under your right index finger is water or land. Then you toss the globe up in the air again and repeat the procedure.41 This strategy generates a sequence of surface samples from the globe. The first nine samples might look like:
-->
&emsp;&emsp;假设我们有一个地球的模型。这个模型可以攥在手里。现在你很好奇地球表面到底有多大面积是水。方法如下：把模型抛到空中，然后用手接住，记录下你的右手食指的地方是水还是陆地。重复此过程。最后得到一个关于地球表面的采样序列。假设前9个数据如下：
<p align="center"> 
W L W W W L W L W
</p>

<!--
where W indicates water and L indicates land. So in this example you observe six W (water) observations and three L (land) observations. Call this sequence of observations the data.
-->
W代表水，L代表陆地。所以在这个例子中，观测到6次水和3次陆地。这个观测结果就是我们的数据。

<!--
To get the logic moving, we need to make assumptions, and these assumptions constitute the model. Designing a simple Bayesian model benefits from a design loop with three steps.

(1) Data story: Motivate the model by narrating how the data might arise.
(2) Update: Educate your model by feeding it the data.
(3) Evaluate: All statistical models require supervision, leading possibly to model revi-
sion.
The next sections walk through these steps, in the context of the globe tossing evidence.
-->

为了使模型奏效，我们还需要做一些基本的构建模型的假设。构建贝叶斯模型大约需要以下三个步骤：

1. 数据故事：通过叙述数据是怎么产生的来构想出模型
2. 更新：把数据喂给模型来训练
3. 评估：所有的统计模型都需要监督，不断修正。

下面的章节我们会通过地球模型的例子来展示这些步骤

<!--
2.2.1. A data story. Bayesian data analysis usually means producing a story for how the data came to be. This story may be descriptive, specifying associations that can be used to predict outcomes, given observations. Or it may be causal, a theory of how some events produce other events. Typically, any story you intend to be causal may also be descriptive. But many descriptive stories are hard to interpret causally. But all data stories are complete, in the sense that they are sufficient for specifying an algorithm for simulating new data. In the next chapter, you’ll see examples of doing just that, as simulating new data is a useful part of model criticism.
-->

**2.1.1 数据故事**。贝叶斯数据分析通常意味着要讲一个数据是怎样的故事。故事可能是*描述性*的，给定观测数据的情况下找出数据之间的关联从而用来预测。也可能是*归因*（一种事件之间因果关系的理论）。通常归因也是描述。但是描述通常很难归因。但通常数据故事都是完备的，可以用来训练算法来模拟新数据。下一章会介绍一些实例，因为模拟新数据是模型评价的重要部分。

<!--
You can motivate your data story by trying to explain how each piece of data is born. This usually means describing aspects of the underlying reality as well as the sampling process. The data story in this case is simply a restatement of the sampling process:
-->
&emsp;&emsp; 数据故事可以讲一下数据的每一部分都是怎么产生的。通常包含背后的事实和采样过程。在这个例子中可以这样简单的陈述：

<!--
1. The true proportion of water covering the globe is p.
2. Asingletossoftheglobehasaprobabilitypofproducingawater(W)observation.
It has a probability 1 − p of producing a land (L) observation.
3. Each toss of the globe is independent of the others.
-->

1. 地球上水的比例设为p
2. 每次抛球采样得到水的比例为 p，观测到陆地的比例为1-p
3. 每次抛球取样都是独立的
<!--
The data story is then translated into a formal probability model. This probability model is easy to build, because the construction process can be usefully broken down into a series of component decisions. Before meeting these components, however, it’ll be useful to visualize how a Bayesian model behaves. After you’ve become acquainted with how such a model learns from data, we’ll pop the machine open and investigate its engineering.
-->
&emsp;&emsp;然后把数据故事转换成形式化的概率模型。这个模型比较容易，因为构建过程可以分解为一系列离散的过程。在展示这些过程之前，我们先来画一下贝叶斯模型有一些直观感受。

<!--
After you’ve become acquainted with how such a model learns from data, we’ll pop the machine open and investigate its engineering.
-->

&emsp;&emsp;一旦熟悉了怎么从数据建立模型，我们就开动机器，深入研究其工程原理。

<!--
Rethinking: The value of storytelling. The data story has value, even if you quickly abandon it and never use it to build a model or simulate new observations. Indeed, it is important to eventually discard the story, because many different stories always correspond to the same model. As a result, showing that a model does a good job does not in turn uniquely support our data story. Still, the story has value because in trying to outline the story, often one realizes that additional questions must be answered. Most data stories are much more specific than are the verbal hypotheses that inspire data collection. Hypotheses can be vague, such as “it’s more likely to rain on warm days.” When you are forced to consider sampling and measurement and make a precise statement of how temperature predicts rain, many stories and resulting models will be consistent with the same vague hypothesis. Resolving that ambiguity often leads to important realizations and model revisions, before any model is fit to data.
-->

>思考：讲故事的重要性。数据故事有它的价值，虽然大多数时候我们都是把它撇到一边，对建模和模拟新数据也没什么用。确实，把数据故事剔除找到本质非常重要，因为很多不同的故事最后都归结为相同的模型。所以虽然有时模型的表现的很好，但并不意味着能支撑数据故事。但是，即便如此数据故事有它存在的意义，可能在讲故事的过程中，会帮我们发现很多问题。大多数的数据故事比一些口头的假设更具体。假设可能是模糊的，比如：“温暖的天气更容易下雨”。当做一个用温度预测下雨的模型时，假设可能就会变成这样。在真正选择模型之前，先把这些模糊性解决掉可能会更加清晰并有所发现。

<!--
2.2.2. Bayesian updating. Our problem is one of using the evidence—the sequence of globe tosses—to decide among different possible proportions of water on the globe. These pro- portions are like the conjectured marbles inside the bag, from earlier in the chapter. Each possible proportion may be more or less plausible, given the evidence. A Bayesian model be- gins with one set of plausibilities assigned to each of these possibilities. These are the prior plausibilities. Then it updates them in light of the data, to produce the posterior plausibil- ities. This updating process is a kind of learning, called Bayesian updating. The details of this updating—how it is mechanically achieved—can wait until later in the chapter. For now, let’s look only at how such a machine behaves.
-->
**2.2.2 贝叶斯更新**。我们要解决的问题是用抛地球模型所得到的序列来决定地球上水的到底占多少比例。众多可能的比例就像本章一开始的例子里袋子里的小球的可能组合一样。在给定数据的情况下每种比例的可能性不同。贝叶斯模型开始的时候给这些可能性分配一系列可能性。就是所谓的先验。然后利用看到的数据去更新模型，从而得到一个后验概率。这个更新的过程其实是一种学习的过程，我们叫它贝叶斯更新。细节我们后面再讲，先来看看它的运作机制。

<!--
For the sake of the example only, let’s program our Bayesian machine to initially assign the same plausibility to every proportion of water, every value of p. Now look at the top-left plot in Figure 2.5. The dashed horizontal line represents this initial plausibility of each pos- sible value of p. After seeing the first toss, which is a “W,” the model updates the plausibilities to the solid line. The plausibility of p = 0 has now fallen to exactly zero—the equivalent of
“impossible.” Why? Because we observed at least one speck of water on the globe, so now we know there is some water. The model executes this logic automatically. You don’t have it in- struct it to account for this consequence. Probability theory takes care of it for you, because it is essentially counting paths through the garden of forking data, as in the previous section.
-->

&emsp;&emsp;简单起见，开始的时候把每一个可能的水的比例都设为一样的，也就是每个p值的概率都一样。看一下图2.5的左上角，水平虚线代表的是每个点的p值的概率。第一次抛球以后，得到的结果是“W”，模型就被更新为实线的样子。现在p=0的概率已经为零了，也就是不可能了。为什么？因为我们观察到了水，所以我们已经知道地球上一定有水。模型自动完成这个更新逻辑。整个过程不需要人工干预。概率理论来完成这个更新过程，就跟上一节我们所讲的一样，概率理论帮我们数花园中的路径数。

<!--
Likewise, the plausibility of p > 0.5 has increased. This is because there is not yet any evidence that there is land on the globe, so the initial plausibilities are modified to be consis- tent with this. Note however that the relative plausibilities are what matter, and there isn’t yet much evidence. So the differences in plausibility are not yet very large. In this way, the amount of evidence seen so far is embodied in the plausibilities of each value of p.
-->

&emsp;&emsp;同样，p>0.5的可能性增加了。因为目前为止没有证据表明地球上有陆地，所以初始的可能性就被更新成现在的样子。这里需要注意的是合理性的相对值才有意义，并且目前为止证据也很少。所以可能性的差异还不是很大。证据的数量以这种形式隐含在p的每个取值的可能性中。

<!--
In the remaining plots in Figure 2.5, the additional samples from the globe are intro- duced to the model, one at a time. Each dashed curve is just the solid curve from the previous plot, moving left to right and top to bottom. Every time a “W” is seen, the peak of the plausi- bility curve moves to the right, towards larger values of p. Every time an “L” is seen, it moves the other direction. The maximum height of the curve increases with each sample, meaning that fewer values of p amass more plausibility as the amount of evidence increases. As each new observation is added, the curve is updated consistent with all previous observations.
-->
&emsp;&emsp;图2-5其余的部分，每幅图都加入一个新的数据。每条虚线是前一个图的实现部分，顺序是从左到右从上到下。每多一个“W”可能性曲线向右移动一点点，也就是向p取值比较大的方向。每多一个“L”，就会将曲线向相反的方向移动。曲线的最大高度在不断的升高，也就是说随着证据的增多越来越少的p值的集合占据了大部分可能性。没新加入一个观测值，就会在前面的基础上更新曲线。

<!--
Notice that every updated set of plausibilities becomes the initial plausibilities for the next observation. Every conclusion is the starting point for future inference. However, this updating process works backwards, as well as forwards. Given the final set of plausibilities in the bottom-right plot of Figure 2.5, and knowing the final observation (W), it is possible to mathematically divide out the observation, to infer the previous plausibility curve. So the data could be presented to your model in any order, or all at once even. In most cases, you will present the data all at once, for the sake of convenience. But it’s important to realize that this merely represents abbreviation of an iterated learning process.
-->

&emsp;&emsp;注意每次可能性集合都会变成下一次更新的初始值。每一个结论都是下一次推断的起点。但是更新过程不光可以向前，向后也是可以的。如果图2-5右下角最后的可能性集合已知，并且最后的观测值（W）已知，当然数学上可以把观测值除出来，上一个可能性曲线是可以推到出来的。所以模型中的数据可以以任何顺序展现，甚至两个方向同时展现。方便起见，大多数时候，我们一次把所有数据展示出来。但是一定得知道这是一个渐进式的学习过程。

<!--
Rethinking: Sample size and reliable inference. It is common to hear that there is a minimum num- ber of observations for a useful statistical estimate. For example, there is a widespread superstition that 30 observations are needed before one can use a Gaussian distribution. Why? In non-Bayesian statistical inference, procedures are often justified by the method’s behavior at very large sample sizes, so-called asymptotic behavior. As a result, performance at small samples sizes is questionable.
In contrast, Bayesian estimates are valid for any sample size. This does not mean that more data isn’t helpful—it certainly is. Rather, the estimates have a clear and valid interpretation, no matter the sample size. But the price for this power is dependency upon the initial estimates, the prior. If the prior is a bad one, then the resulting inference will be misleading. There’s no free lunch,42 when it comes to learning about the world. A Bayesian golem must choose an initial plausibility, and a non-Bayesian golem must choose an estimator. Both golems pay for lunch with their assumptions.
-->

>思考：样本量和可靠推断。我们可能经常听说一个有效的统计估计的样本量有一个最小值。比如，对一个高斯分布大家普遍认为至少得有30个观测值。为什么？因为在非贝叶斯统计中，通常需要在大样本量中得到验证，也就是所谓的渐进式性。所以在小样本集上的表现，非贝叶斯统计就比较差。但是贝叶斯统计在小样本上就比较有效。这不是说大数据集对统计没用。而是估计有一个清晰并且有效的解释，并且跟样本量没关系。但是贝叶斯统计的这个时候又严重依赖于初始值也就是先验。如果先验不好，那么推断结果也就会被误导。天下没有免费的午餐。贝叶斯统计必须选定一个初始的可能性，非贝叶斯统计必须选一个估计值。两种统计都以假设为代价。

<!--
2.2.3. Evaluate. The Bayesian model learns in a way that is demonstrably optimal,provided that the real, large world is accurately described by the model. This is to say that your Bayesian machine guarantees perfect inference, within the small world. No other way of using the available information, and beginning with the same state of information, could do better.
-->

**2.2.3 评估**。理论上讲如果模型能够准确的描述现实世界，贝叶斯模型明显是以一种最优的方式学习。也就是说贝叶斯模型在小世界中能保证是完美的推断。如果已知信息相同，没有其他的方式能够比贝叶斯推断做的更好。

<!--
Don’t get too excited about this logical virtue, however. The calculations may malfunc- tion, so results always have to be checked. And if there are important differences between the model and reality, then there is no logical guarantee of large world performance. And even if the two worlds did match, any particular sample of data could still be misleading. So it’s worth keeping in mind at least two cautious principles.
-->

&emsp;&emsp;但是逻辑完美不用太在意。计算过程也可能是错的，所以结果必须经过验证。而且如果模型和现实有太大的差距，模型在现实世界中的表现就不那么有效了。即使是表现一致，某个特定数据也可能把模型引入歧途。所以两条原则必须谨记：

<!--
First, the model’s certainty is no guarantee that the model is a good one. As the amount of data increases, the globe tossing model will grow increasingly sure of the proportion of water. This means that the curves in Figure 2.5 will become increasingly narrow and tall, restricting plausible values within a very narrow range. But models of all sorts—Bayesian or not—can be very confident about an estimate, even when the model is seriously misleading. This is because the estimates are conditional on the model. What your model is telling you is that, given a commitment to this particular model, it can be very sure that the plausible values are in a narrow range. Under a different model, things might look differently.
-->

&emsp;&emsp;第一，模型的确定性并不能保证模型就是一个好模型。随着数据量的增大，抛地球的模型对水的比例会越来越确定。图2-5的曲线会变得越来越窄越来越高，也就是可能性的取值会限制在一个很窄的范围内。但是所有模型，贝叶斯的或者非贝叶斯的，即使模型是错的也能找到一个非常有信心的估计值。模型所能告诉你的只是在现在这个模型下，可能的取值在一个很窄的范围内。换一个模型，就都变了。

<!--
Second, it is important to supervise and critique your model’s work. Consider again the fact that the updating in the previous section works in any order of data arrival. We could shuffle the order of the observations, as long as six W’s and three L’s remain, and still end up with the same final plausibility curve. That is only true, however, because the model assumes that order is irrelevant to inference. When something is irrelevant to the machine, it won’t affect the inference directly. But it may affect it indirectly, because the data will depend upon order. So it is important to check the model’s inferences in light of aspects of the data it does not know about. Such checks are an inherently creative enterprise, left to the analyst and the scientific community. Golems are very bad at it.
-->

&emsp;&emsp;第二，深入模型的细节很重要。想一下前面章节例子中数据的顺序。我们可以把数据的循序打乱，只要保证有6个“W”和3个“L”，最终结果都是一样的。这种情况当且仅当模型假设顺序和推断不相关。不想关也就对推断结果没有直接的影响。所以从模型没有考虑到的因素对模型推断结果进行评价非常重要。这种检测非常需要灵感，需要分析师和科学家来参与。机器人不擅长这个。

<!--
In Chapter 3, you’ll see some examples of such checks. For now, note that the goal is not to test the truth value of the model’s assumptions. We know the model’s assumptions are never exactly right, in the sense of matching the true data generating process. Therefore there’s no point in checking if the model is true. Failure to conclude that a model is false must be a failure of our imagination, not a success of the model. Moreover, models do not need to be exactly true in order to produce highly precise and useful inferences. All manner of small world assumptions about error distributions and the like can be violated in the large world, but a model may still produce a perfectly useful estimate. This is because models are essentially information processing machines, and there are some surprising aspects of information that cannot be easily captured by framing the problem in terms of the truth of assumptions.43
-->

&emsp;&emsp;在第三章会有一些关于评价的例子。现在请注意，评价的目标不是检测模型假设的正确性。模型的假设永远不能完美解释数据的生成过程。所以检查模型是不是正确其实没什么意义。在选择模型之前在我们的脑子里其实已经把错误的模型剔除掉了。而且模型不一定非得十分精确也能产生准确的结果和有用的推断。小世界中关于错误的分布多多少少都和现实世界有冲突，但是不妨碍它产生相对完美的估计值。因为模型本质上还是一个信息处理机，有些信息在完美假设的情况下实际没法获取。

<!--
Instead, the objective is to check the model’s adequacy for some purpose. This usually means asking and answering additional questions, beyond those that originally constructed the model. Both the questions and answers will depend upon the scientific context. So it’s hard to provide general advice. There will be many examples, throughout the book, and of course the scientific literature is replete with evaluations of the suitability of models for different jobs—prediction, comprehension, measurement, and persuasion.
-->

&emsp;&emsp;所以，评价的目标是检查模型在某种情况下的充分性。通常是提问和回答一些额外的超出构建模型时的问题。在具体的科学背景下的提问和回答。所以很难有很具体的建议。本书中会有很多的例子，当然在科学文献中也有很多不同背景下对模型的评价，包括预测、解释、观测以及说服。

<!--
Rethinking: Deflationary statistics. It may be that Bayesian inference is the best general purpose method of inference known. However, Bayesian inference is much less powerful than we’d like it to be. There is no approach to inference that provides universal guarantees. No branch of applied mathematics has unfettered access to reality, because math is not discovered, like the proton. Instead it is invented, like the shovel.44
-->

>思考：泼点冷水。贝叶斯统计是已知的最具有通用性的统计方法。但是贝叶斯统计远没有我们想象的强大。它不保证有通用。其实应用数学中就没有一个分支跟真实世界能完美贴合，因为数学不是像质子那样被发现的，而是像铲子那样被发明出来的。



